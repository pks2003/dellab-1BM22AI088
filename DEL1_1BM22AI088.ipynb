{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67517e2a-6af9-4acb-a5f1-cd4a46c2c32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "Confusion Matrix: {(0, 0): 3, (1, 1): 1, (0, 1): 0, (1, 0): 0}\n",
      "Input: [0, 0], Predicted Output: 0\n",
      "Input: [0, 1], Predicted Output: 0\n",
      "Input: [1, 0], Predicted Output: 0\n",
      "Input: [1, 1], Predicted Output: 1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "class SingleLayerPerceptron:\n",
    "    def __init__(self, input_size, learning_rate=0.01, initial_weights=None):\n",
    "        if initial_weights is not None:\n",
    "            if len(initial_weights) != input_size:\n",
    "                raise ValueError(f\"Expected {input_size} weights, but got {len(initial_weights)}.\")\n",
    "            self.weights = initial_weights\n",
    "        else:\n",
    "            self.weights = [random.uniform(-0.5, 0.5) for _ in range(input_size)]\n",
    "        self.bias = random.uniform(-0.5, 0.5)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def step(self, x):\n",
    "        return 1 if x >= 0 else 0\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        weighted_sum = sum(w * x for w, x in zip(self.weights, inputs)) + self.bias\n",
    "        return self.step(weighted_sum)\n",
    "\n",
    "    def train(self, training_data, labels, epochs):\n",
    "        for _ in range(epochs):\n",
    "            for inputs, label in zip(training_data, labels):\n",
    "                weighted_sum = sum(w * x for w, x in zip(self.weights, inputs)) + self.bias\n",
    "                output = self.step(weighted_sum)\n",
    "                error = label - output\n",
    "                for i in range(len(self.weights)):\n",
    "                    self.weights[i] += self.learning_rate * error * inputs[i]\n",
    "                self.bias += self.learning_rate * error\n",
    "\n",
    "    def evaluate(self, test_data, test_labels):\n",
    "        correct_predictions = 0\n",
    "        confusion_matrix = defaultdict(int)\n",
    "        for inputs, label in zip(test_data, test_labels):\n",
    "            prediction = self.predict(inputs)\n",
    "            predicted_label = prediction\n",
    "            confusion_matrix[(label, predicted_label)] += 1\n",
    "            if predicted_label == label:\n",
    "                correct_predictions += 1\n",
    "\n",
    "        accuracy = correct_predictions / len(test_labels) if test_labels else 0\n",
    "        precision = confusion_matrix[(1, 1)] / (confusion_matrix[(1, 1)] + confusion_matrix[(0, 1)]) if (confusion_matrix[(1, 1)] + confusion_matrix[(0, 1)]) > 0 else 0\n",
    "        recall = confusion_matrix[(1, 1)] / (confusion_matrix[(1, 1)] + confusion_matrix[(1, 0)]) if (confusion_matrix[(1, 1)] + confusion_matrix[(1, 0)]) > 0 else 0\n",
    "        f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score,\n",
    "            'confusion_matrix': confusion_matrix\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    training_data = [\n",
    "        [0, 0],  \n",
    "        [0, 1],  \n",
    "        [1, 0],  \n",
    "        [1, 1]   \n",
    "    ]\n",
    "    labels = [0, 0, 0, 1]\n",
    "    input_size = len(training_data[0])\n",
    "    perceptron = SingleLayerPerceptron(input_size=input_size)\n",
    "    perceptron.train(training_data, labels, epochs=1000)\n",
    "    metrics = perceptron.evaluate(training_data, labels)\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.2f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "    print(f\"F1 Score: {metrics['f1_score']:.2f}\")\n",
    "    print(f\"Confusion Matrix: {dict(metrics['confusion_matrix'])}\")\n",
    "    for inputs in training_data:\n",
    "        prediction = perceptron.predict(inputs)\n",
    "        print(f\"Input: {inputs}, Predicted Output: {prediction}\")\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ed7b28-a1c6-4913-af99-86415823cc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "Confusion Matrix: {(0, 0): 3, (1, 0): 1, (1, 1): 0, (0, 1): 0}\n",
      "Input: [0, 0], Predicted Output: 0.2336\n",
      "Input: [0, 1], Predicted Output: 0.3275\n",
      "Input: [1, 0], Predicted Output: 0.3508\n",
      "Input: [1, 1], Predicted Output: 0.4633\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "class SingleLayerPerceptron:\n",
    "    def __init__(self, input_size, learning_rate=0.01, initial_weights=None):\n",
    "        if initial_weights is not None:\n",
    "            if len(initial_weights) != input_size:\n",
    "                raise ValueError(f\"Expected {input_size} weights, but got {len(initial_weights)}.\")\n",
    "            self.weights = initial_weights\n",
    "        else:\n",
    "            self.weights = [random.uniform(-0.5, 0.5) for _ in range(input_size)]\n",
    "\n",
    "        self.bias = random.uniform(-0.5, 0.5)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "\n",
    "        return 1 / (1 + self.exp(-x))\n",
    "\n",
    "    def exp(self, x):\n",
    "        \n",
    "        if x < -709:\n",
    "            return 0\n",
    "        elif x > 709:\n",
    "            return float('inf')\n",
    "        else:\n",
    "            return 2.718281828459045 ** x\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        weighted_sum = sum(w * x for w, x in zip(self.weights, inputs)) + self.bias\n",
    "        return self.sigmoid(weighted_sum)\n",
    "\n",
    "    def train(self, training_data, labels, epochs):\n",
    "        for _ in range(epochs):\n",
    "            for inputs, label in zip(training_data, labels):\n",
    "                weighted_sum = sum(w * x for w, x in zip(self.weights, inputs)) + self.bias\n",
    "                output = self.sigmoid(weighted_sum)\n",
    "                error = label - output\n",
    "                for i in range(len(self.weights)):\n",
    "                    self.weights[i] += self.learning_rate * error * output * (1 - output) * inputs[i]\n",
    "                self.bias += self.learning_rate * error * output * (1 - output)\n",
    "\n",
    "    def evaluate(self, test_data, test_labels):\n",
    "        correct_predictions = 0\n",
    "        confusion_matrix = defaultdict(int)\n",
    "        for inputs, label in zip(test_data, test_labels):\n",
    "            prediction = self.predict(inputs)\n",
    "            predicted_label = 1 if prediction >= 0.5 else 0\n",
    "            confusion_matrix[(label, predicted_label)] += 1\n",
    "            if predicted_label == label:\n",
    "                correct_predictions += 1\n",
    "\n",
    "        accuracy = correct_predictions / len(test_labels) if test_labels else 0\n",
    "        precision = confusion_matrix[(1, 1)] / (confusion_matrix[(1, 1)] + confusion_matrix[(0, 1)]) if (confusion_matrix[(1, 1)] + confusion_matrix[(0, 1)]) > 0 else 0\n",
    "        recall = confusion_matrix[(1, 1)] / (confusion_matrix[(1, 1)] + confusion_matrix[(1, 0)]) if (confusion_matrix[(1, 1)] + confusion_matrix[(1, 0)]) > 0 else 0\n",
    "        f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score,\n",
    "            'confusion_matrix': confusion_matrix\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    training_data = [\n",
    "        [0, 0],  \n",
    "        [0, 1], \n",
    "        [1, 0],  \n",
    "        [1, 1]   \n",
    "    ]\n",
    "    labels = [0, 0, 0, 1]\n",
    "    input_size = len(training_data[0])\n",
    "    perceptron = SingleLayerPerceptron(input_size=input_size)\n",
    "    perceptron.train(training_data, labels, epochs=1000)\n",
    "    metrics = perceptron.evaluate(training_data, labels)\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.2f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "    print(f\"F1 Score: {metrics['f1_score']:.2f}\")\n",
    "    print(f\"Confusion Matrix: {dict(metrics['confusion_matrix'])}\")\n",
    "    for inputs in training_data:\n",
    "        prediction = perceptron.predict(inputs)\n",
    "        print(f\"Input: {inputs}, Predicted Output: {prediction:.4f}\")\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d55488e-b466-48d6-9090-99633227447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "Confusion Matrix: {(0, 0): 4, (1, 1): 2, (0, 1): 0, (1, 0): 0}\n",
      "Input: [5.1, 3.5, 1.4], Predicted Output: 0.0641\n",
      "Input: [4.9, 3.0, 1.4], Predicted Output: 0.1088\n",
      "Input: [4.7, 3.2, 1.3], Predicted Output: 0.0788\n",
      "Input: [5.0, 3.6, 1.4], Predicted Output: 0.0582\n",
      "Input: [7.0, 3.2, 4.7], Predicted Output: 0.9176\n",
      "Input: [6.4, 3.2, 4.5], Predicted Output: 0.8969\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "class SingleLayerPerceptron:\n",
    "    def __init__(self, input_size, learning_rate=0.01, initial_weights=None):\n",
    "        if initial_weights is not None:\n",
    "            if len(initial_weights) != input_size:\n",
    "                raise ValueError(f\"Expected {input_size} weights, but got {len(initial_weights)}.\")\n",
    "            self.weights = initial_weights\n",
    "        else:\n",
    "            self.weights = [random.uniform(-0.5, 0.5) for _ in range(input_size)]\n",
    "        self.bias = random.uniform(-0.5, 0.5)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + self.exp(-x))\n",
    "\n",
    "    def exp(self, x):\n",
    "        if x < -709:\n",
    "            return 0\n",
    "        elif x > 709:\n",
    "            return float('inf')\n",
    "        else:\n",
    "            return 2.718281828459045 ** x\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        weighted_sum = sum(w * x for w, x in zip(self.weights, inputs)) + self.bias\n",
    "        return self.sigmoid(weighted_sum)\n",
    "\n",
    "    def train(self, training_data, labels, epochs):\n",
    "        for _ in range(epochs):\n",
    "            for inputs, label in zip(training_data, labels):\n",
    "                weighted_sum = sum(w * x for w, x in zip(self.weights, inputs)) + self.bias\n",
    "                output = self.sigmoid(weighted_sum)\n",
    "                error = label - output\n",
    "                for i in range(len(self.weights)):\n",
    "                    self.weights[i] += self.learning_rate * error * output * (1 - output) * inputs[i]\n",
    "                self.bias += self.learning_rate * error * output * (1 - output)\n",
    "\n",
    "    def evaluate(self, test_data, test_labels):\n",
    "        correct_predictions = 0\n",
    "        confusion_matrix = defaultdict(int)\n",
    "        for inputs, label in zip(test_data, test_labels):\n",
    "            prediction = self.predict(inputs)\n",
    "            predicted_label = 1 if prediction >= 0.5 else 0\n",
    "            confusion_matrix[(label, predicted_label)] += 1\n",
    "            if predicted_label == label:\n",
    "                correct_predictions += 1\n",
    "        accuracy = correct_predictions / len(test_labels) if test_labels else 0\n",
    "        precision = confusion_matrix[(1, 1)] / (confusion_matrix[(1, 1)] + confusion_matrix[(0, 1)]) if (confusion_matrix[(1, 1)] + confusion_matrix[(0, 1)]) > 0 else 0\n",
    "        recall = confusion_matrix[(1, 1)] / (confusion_matrix[(1, 1)] + confusion_matrix[(1, 0)]) if (confusion_matrix[(1, 1)] + confusion_matrix[(1, 0)]) > 0 else 0\n",
    "        f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score,\n",
    "            'confusion_matrix': confusion_matrix\n",
    "        }\n",
    "\n",
    "def load_csv(filename):\n",
    "    try:\n",
    "        data_frame = pd.read_csv(filename)\n",
    "        data = data_frame.iloc[:, :-1].values.tolist()  \n",
    "        labels = data_frame.iloc[:, -1].tolist()       \n",
    "        return data, labels\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filename}' was not found.\")\n",
    "        exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "def main():\n",
    "    filename = 'feature.csv'\n",
    "    training_data, labels = load_csv(filename)\n",
    "    input_size = len(training_data[0])\n",
    "    perceptron = SingleLayerPerceptron(input_size=input_size)\n",
    "    perceptron.train(training_data, labels, epochs=1000)\n",
    "    metrics = perceptron.evaluate(training_data, labels)\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.2f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "    print(f\"F1 Score: {metrics['f1_score']:.2f}\")\n",
    "    print(f\"Confusion Matrix: {dict(metrics['confusion_matrix'])}\")\n",
    "    for inputs in training_data:\n",
    "        prediction = perceptron.predict(inputs)\n",
    "        print(f\"Input: {inputs}, Predicted Output: {prediction:.4f}\")\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78969da4-e9dd-4b19-9306-22add08cfe3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "Confusion Matrix: {(0, 0): 4, (1, 1): 2, (0, 1): 0, (1, 0): 0}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 3 features separated by commas (or 'exit' to quit):  0.4,0.2,0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output: 1 (Probability: 0.6286)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 3 features separated by commas (or 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "class SingleLayerPerceptron:\n",
    "    def __init__(self, input_size, learning_rate=0.01, initial_weights=None):\n",
    "        if initial_weights is not None:\n",
    "            if len(initial_weights) != input_size:\n",
    "                raise ValueError(f\"Expected {input_size} weights, but got {len(initial_weights)}.\")\n",
    "            self.weights = initial_weights\n",
    "        else:\n",
    "            self.weights = [random.uniform(-0.5, 0.5) for _ in range(input_size)]\n",
    "        self.bias = random.uniform(-0.5, 0.5)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + self.exp(-x))\n",
    "\n",
    "    def exp(self, x):\n",
    "        if x < -709:\n",
    "            return 0\n",
    "        elif x > 709:\n",
    "            return float('inf')\n",
    "        else:\n",
    "            return 2.718281828459045 ** x\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        weighted_sum = sum(w * x for w, x in zip(self.weights, inputs)) + self.bias\n",
    "        return self.sigmoid(weighted_sum)\n",
    "\n",
    "    def train(self, training_data, labels, epochs):\n",
    "        for _ in range(epochs):\n",
    "            for inputs, label in zip(training_data, labels):\n",
    "                weighted_sum = sum(w * x for w, x in zip(self.weights, inputs)) + self.bias\n",
    "                output = self.sigmoid(weighted_sum)\n",
    "                error = label - output\n",
    "                for i in range(len(self.weights)):\n",
    "                    self.weights[i] += self.learning_rate * error * output * (1 - output) * inputs[i]\n",
    "                self.bias += self.learning_rate * error * output * (1 - output)\n",
    "\n",
    "    def evaluate(self, test_data, test_labels):\n",
    "        correct_predictions = 0\n",
    "        confusion_matrix = defaultdict(int)\n",
    "        for inputs, label in zip(test_data, test_labels):\n",
    "            prediction = self.predict(inputs)\n",
    "            predicted_label = 1 if prediction >= 0.5 else 0\n",
    "            confusion_matrix[(label, predicted_label)] += 1\n",
    "            if predicted_label == label:\n",
    "                correct_predictions += 1\n",
    "        accuracy = correct_predictions / len(test_labels) if test_labels else 0\n",
    "        precision = confusion_matrix[(1, 1)] / (confusion_matrix[(1, 1)] + confusion_matrix[(0, 1)]) if (confusion_matrix[(1, 1)] + confusion_matrix[(0, 1)]) > 0 else 0\n",
    "        recall = confusion_matrix[(1, 1)] / (confusion_matrix[(1, 1)] + confusion_matrix[(1, 0)]) if (confusion_matrix[(1, 1)] + confusion_matrix[(1, 0)]) > 0 else 0\n",
    "        f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score,\n",
    "            'confusion_matrix': confusion_matrix\n",
    "        }\n",
    "\n",
    "def load_csv(filename):\n",
    "    try:\n",
    "        data_frame = pd.read_csv(filename)\n",
    "        data = data_frame.iloc[:, :-1].values.tolist()  \n",
    "        labels = data_frame.iloc[:, -1].tolist()       \n",
    "        return data, labels\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filename}' was not found.\")\n",
    "        exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "def main():   \n",
    "    filename = 'feature.csv'\n",
    "    training_data, labels = load_csv(filename)\n",
    "    input_size = len(training_data[0])\n",
    "    perceptron = SingleLayerPerceptron(input_size=input_size)   \n",
    "    perceptron.train(training_data, labels, epochs=1000)   \n",
    "    metrics = perceptron.evaluate(training_data, labels)\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.2f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "    print(f\"F1 Score: {metrics['f1_score']:.2f}\")\n",
    "    print(f\"Confusion Matrix: {dict(metrics['confusion_matrix'])}\")   \n",
    "    while True:\n",
    "        user_input = input(f\"Enter {input_size} features separated by commas (or 'exit' to quit): \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            break\n",
    "        try:\n",
    "            new_inputs = [float(x) for x in user_input.split(',')]\n",
    "            if len(new_inputs) != input_size:\n",
    "                print(f\"Please enter exactly {input_size} features.\")\n",
    "                continue\n",
    "            prediction = perceptron.predict(new_inputs)\n",
    "            predicted_label = 1 if prediction >= 0.5 else 0\n",
    "            print(f\"Predicted Output: {predicted_label} (Probability: {prediction:.4f})\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter numeric values.\")\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b745a-8f74-46ef-ad42-9b5e53be3726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
